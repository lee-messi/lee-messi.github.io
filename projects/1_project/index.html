<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> My Research | Messi H.J. Lee </title> <meta name="author" content="Messi H.J. Lee"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="messi-lee, messi"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lee-messi.github.io/projects/1_project/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Messi</span> H.J. Lee </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">My Research</h1> <p class="post-description"></p> </header> <article> <p>This blog post is an introduction to my research - what I am interested in, how I approach those issues, and how they relate to each other. If you would like to discuss my research and have any insights to share, don’t hesistate to email me at hojunlee[at]wustl[dot]edu.</p> <h3 id="the-outgroup-homogeneity-effect">The Outgroup Homogeneity Effect</h3> <p>Social psychologists have long studied a phenomenon referred to as the <em>outgroup homogeneity effect</em>. This phenomenon refers to a tendency of individuals to perceive members of <em>outgroups</em> as more homogeneous than members of <em>ingroups</em>. Here, ingroup refers to the group that someone identifies with while outgroup refers to the group that one <em>does not</em> identify with. For example, as a student of Washington University in St. Louis, I would identify other students at WashU as my ingroup whereas I would identify students at other schools as my outgroup, and according to the <em>outgroup homogeneity effect</em>, I have the tendency to perceive students at other schools as more homogeneous and less diverse than students at WashU.</p> <p>A number of explanations explain this phenomenon. One is <em>contact</em>. Naturally, we are more likely to come into contact with ingroup members than outgroup members. For exmaple, I am more likely to come across different students at WashU, taking classes or going to and from the lab, than I am to come across students at other schools. Because I come across more students at WashU, of different majors, looks, styles, personality … etc., I can perceive them as more diverse. On the other hand, I am more likely to generalize based on the limited observations I’ve made, if any, about other groups, and perceive them that way.</p> <p>Another explanation has to do with the <em>social-categorization theory</em>. The theory posits that individuals tend to classify themselves into groups and that the dynamic between these groups affects our behavior towards others. For example, when we come into contact with an outgroup member, we are more likely to pay attention to the difference between gorups as opposed to difference <em>within</em> groups. This results in a more heterogeneous perception of the outgroup. On the other hand, when coming into contact with an ingroup member, we are more likely to focus on the <em>within</em> group differences, which leads to a more heterogeneous perception of the ingroup.</p> <h3 id="outgroup-homogeneity-effect-in-the-context-of-group-powerstatus">Outgroup Homogeneity Effect in the Context of Group Power/Status</h3> <p>The outgroup homogeneity effect is specific to the intergroup context (i.e., the ingroup-outgroup context), but the perception of a group as more or less homogeneous extends to other contexts as well. The context that my research focuses on is <em>group power</em>: if power affects the homogeneity that we associate with a group. What’s interesting is that in the group power context, we observe unique patterns that deviate from the outgroup homogeneity effect. That is, according to the outgroup homogeneity effect, the group in power, say the racial majority in the United States – White Americans – are likely to perceive members of their outgroup – racial minority groups as more homogeneous. The opposite is to be expected for racial minority group members: they would perceive members of their outgroup – White Americans – as more homogeneous.</p> <p>Surprisingly, research finds that only half of this is true. The group in power exhibits the outgroup homogeneity effect, but the group not in power, or the socially subordiante group, tends to perceive members of their ingroup as more homogeneous than members of their outgroup. These two, altogether, point to a consistent direction where members of both the racial majority and minority perceive members of the racial minority as more homogeneous. This phenomenon is what we refer to as <strong>homogeneity bias</strong> in my work.</p> <p>There is a number of explanations for why this may be. One explanation, which also relates to <em>social categorization theory</em>, is that groups not in power may be motivated to boost intragroup solidarity by focusing on similarities shared within the group. Because they focus on intragroup similarity, they focus less on intragroup differences, and hence perceive the ingroup as more homogeneous. Another explanation is that the outcome of groups not in power depend on the resources of those that are in power, and hence groups not in power are motivated to focus on differentiating traits of those in power. Hence, groups not in power are more likely to focus on differences within their outgroup, which leads to them perceiving their ingroup as more homogeneous. Another interesting explanation is that those in power have access to more broad and diverse real-world outcomes whereas those not in power are constrained to a path they need power and resources to break away from. This real-world disparity in diversity of outcomes also affects perceptions of homogeneity.</p> <h3 id="why-does-homogeneity-bias-matter">Why does Homogeneity Bias Matter?</h3> <p>One outstanding implication of homogeneity bias is that perceiving a group as more homogeneous leads to greater stereotyping, prejudice, and discrimination. When we perceive a group as being more heterogeneous, it also means that we are more likely to associate them with stereotypic traits. These observations have led to social psychological interventions where, in the intervention, individuals are made salient about the heterogeneity of the target group (e.g., their subgroups), which in turn reduces negative prejudice and discrimination against the target group ().</p> <h3 id="bias-in-artifical-intelligence-systems">Bias in Artifical Intelligence Systems</h3> <p>One of the biggest phenomena that happened during my PhD is Artifical Intelligence (AI), particularly Large Language Models (LLMs) and, increasingly, multimodal models. What I find most interesting about this explosion is that LLMs and the like tend to reproduce human-like biases. For example, GPT-3, the LLM that started to catch people’s attention back in 2021, when writing stories about gender groups, reproduce gender stereotypes - they associate male characters with sports, war, crime, and politics, and associate female characters with body parts, family, and emotions (Lucy &amp; Bamman, 2021).</p> <p>My research was motivated by the simple question of: if AI sytems reproduce human-like biases, like stereotyping, would they also reproduce homogeneity bias? Would they represent socially subordinate groups as more homogeneous compared to the dominant groups? The approach to finding an answer to this question was pretty straightforward. We asked an LLM - ChatGPT - to generate a variety of text about racial/ethnic and gender groups, and we measured homogeneity of the generated text.</p> <h3 id="measuring-and-comparing-homogeneity-of-text">Measuring and Comparing Homogeneity of Text</h3> <p>At first, it wasn’t clear to us how we would quantify homogeneity of text. For one, we had to figure out what homogeneity of text meant. Would we consider texts to be homogeneous if they used the same words? What if the texts used the same words but meant the exact opposite things? What if the texts used the same prepositions (e.g., for, to, in) and/or articles (e.g., the, a), words that don’t contribute much to the meaning of the sentence? To ensure that the measure of homogeneity would capture similarity in meaning, we decided to use sentence embeddings - vector representations of text that encode both semantic and syntactic information of text. To measure <em>homogeneity</em> of sentence embeddings, we measured pairwise cosine similarity of the sentence embeddings, a measure of distance between two numeric vectors. The intuition was that if a collection of texts is more homogeneous than a collection of others, they would share significantly higher (pairwise) cosine similarity values.</p> <p>We had measured pairwise cosine similarity values between texts generated for individual prompts. These prompts were specific to race/ethnicity, gender, and text format (e.g., story, biography, self-introduction). On one hand, we wanted to compare cosine similarity values between racial/ethnic and gender groups, but we also wanted to account for the fact that different text formats would share different baseline cosine similarity values. This was based on a simple observation that certain text formats, by default, may be more similar to each other than others. For example, self-introductions tend to contain similar content (e.g., name, job) whereas stories may be more flexible and creative.</p> <h3 id="large-language-models-represent-socially-subordinate-groups-as-more-homogeneous">Large Language Models Represent Socially Subordinate Groups as More Homogeneous</h3> <p>We find that texts generated for racial/ethnic minorities (i.e., African, Asian, and Hispanic Americans) and women share significantly higher cosine similarity values compared to White Americans and men <a class="citation" href="#lee_large_2024">(Lee et al., 2024)</a>. These differences were greater within racial/ethnic groups compared to that within gender groups. Furthermore, the effect of gender was generally consistent within individual racial/ethnic groups, with it being largest within Hispanic Americans. These findings were generally consistent across measurement strategies, measurement strategies referring to the different encoder models used to represent the generated text into numeric vector representations.</p> <div class="row"> <div class="col-sm mt-6 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bert2_race-480.webp 480w,/assets/img/bert2_race-800.webp 800w,/assets/img/bert2_race-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/bert2_race.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-6 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bert2_interaction-480.webp 480w,/assets/img/bert2_interaction-800.webp 800w,/assets/img/bert2_interaction-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/bert2_interaction.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Standardized cosine similarity values of all eight intersectional groups (left) and four racial/ethnic groups (right). Error bars were omitted as confidence intervals were all smaller than 0.001. </div> <p>One possible explanation for the bias was stereotyping or trait associations. Perhaps LLMs rely on similar topics when writing texts about racial/ethnic minorities. To test this possibility, we fitted a Structural Topic Model, a model that identifies latent topics in a collection of text, and we found that, indeed, texts about racial/ethnic minorities were about adversity and hardship more so than White Americans. However, at the same time, cosine similarity between texts about adversity and hardship were significantly greater between racial/ethnic minorities. Furthermore, when we explicitly asked LLMs to generate texts that were not about adversity and hardship, cosine similarity between those texts were significantly greater between racial/ethnic minorities. These findings suggested that homogeneity bias wasn’t entirely driven by stereotyping.</p> <h3 id="where-is-this-bias-coming-from">Where is this Bias Coming From?</h3> <p>In our work, we speculate that homogeneity bias in LLMs is a reproduction of bias in the training data. For one, if humans associate socially subordinate groups with homogeneity, we would expect the same bias to be embedded in the massive collection of text used to train these models. This may take various forms: socially subordinate groups may be subject to greater stereotyping such that their representations are more homogeneous in the training data. Considering that training data of LLMs reflect the worldview of the dominant group (i.e., that of White American men; Bender et al., 2021), it is more likely that the training data is biased against the subordinate group such that they are subject to greater stereotyping (). Furthermore, given the majority status of White Americans, for example, we would expect them to have greater representation in the training data compared to racial/ethnic minorities. Greater representation in the training would mean more diverse contexts, ultimately resulting in more diverse output representations. This is somewhat parallel to how contact affects the outgroup homogeneity effect.</p> <h3 id="homogeneity-bias-in-vision-language-models">Homogeneity Bias in Vision-Language Models?</h3> <p>Large Language Models can now process additional modalities like vision and speech. For example, Vision-Language Models can take in images as inputs and write texts about those images, and it can also generate images in response to text prompts. While these advancements are great, it makes us wonder if the bias extends beyond the text modality and reproduces the bias when processing visual inputs.</p> <p>In subsequent work, we decided to assess homogeneity bias in a Vision-Language Model. This allowed us to address some of the limitations we noticed in our previous work. For example, when assessing bias in LLMs, we had to signal group identity using names or group labels. Unfortunately, names encode a lot more than just group identity, and there’s just not enough group labels. In VLMs, we could signal group identity using image stimuli selected from a database of standardized images constructed for this very purpose: to experimentally signal group identities. We selected 90-ish images for two racial groups (i.e., African and White Americans) and two gender groups (i.e., men and women).</p> <p>In this work, we gave the model a neutral prompt asking it to generate a 30-word story about the individual featured inside the image stimuli supplied to model. Then, we compared the pairwise cosine similarity measure between groups.</p> <h3 id="whats-next">What’s Next?</h3> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div id="lee_large_2024" class="col-sm-10"> <div class="title">Large Language Models Portray Socially Subordinate Groups as More Homogeneous, Consistent with a Bias Observed in Humans</div> <div class="author"> Messi H.J. Lee , Jacob M. Montgomery , and Calvin K. Lai </div> <div class="periodical"> <em>In The 2024 ACM Conference on Fairness, Accountability, and Transparency</em> , Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/lee_large_2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Large language models (LLMs) are becoming pervasive in everyday life, yet their propensity to reproduce biases inherited from training data remains a pressing concern. Prior investigations into bias in LLMs have focused on the association of social groups with stereotypical attributes. However, this is only one form of human bias such systems may reproduce. We investigate a new form of bias in LLMs that resembles a social psychological phenomenon where socially subordinate groups are perceived as more homogeneous than socially dominant groups. We had ChatGPT, a state-of-the-art LLM, generate texts about intersectional group identities and compared those texts on measures of homogeneity. We consistently found that ChatGPT portrayed African, Asian, and Hispanic Americans as more homogeneous than White Americans, indicating that the model described racial minority groups with a narrower range of human experience. ChatGPT also portrayed women as more homogeneous than men, but these differences were small. Finally, we found that the effect of gender differed across racial/ethnic groups such that the effect of gender was consistent within African and Hispanic Americans but not within Asian and White Americans. We argue that the tendency of LLMs to describe groups as less diverse risks perpetuating stereotypes and discriminatory behavior.</p> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Messi H.J. Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: July 28, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>
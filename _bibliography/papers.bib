---

@article{lee_americas_2024,
  title = {America's Racial Framework of Superiority and {{Americanness}} Embedded in Natural Language},
  author = {Lee, Messi H. J. and Montgomery, Jacob M. and Lai, Calvin K.},
  year = {2024},
  month = jan,
  journal = {PNAS Nexus},
  volume = {3},
  number = {1},
  pages = {pgad485},
  issn = {2752-6542},
  doi = {10.1093/pnasnexus/pgad485},
  url = {https://academic.oup.com/pnasnexus/article/3/1/pgad485/7504812}, 
  pdf={lee_americas_2024.pdf}, 
  urldate = {2024-01-27},
  abstract = {America's racial framework can be summarized using two distinct dimensions: superiority/inferiority and Americanness/foreignness. We investigated America's racial framework in a corpus of spoken and written language using word embeddings. Word embeddings place words on a low-dimensional space where words with similar meanings are proximate, allowing researchers to test whether the positions of group and attribute words in a semantic space reflect stereotypes. We trained a word embedding model on the Corpus of Contemporary American English{\textemdash}a corpus of 1 billion words that span 30 years and 8 text categories{\textemdash}and compared the positions of racial/ethnic groups with respect to superiority and Americanness. We found that America's racial framework is embedded in American English. We also captured an additional nuance: Asian people were stereotyped as more American than Hispanic people. These results are empirical evidence that America's racial framework is embedded in American English.},
  copyright = {All rights reserved},
  selected = {true}
}

@misc{lee_effect_2024,
  title = {The {{Effect}} of {{Group Status}} on the {{Variability}} of {{Group Representations}} in {{LLM-generated Text}}},
  author = {Lee, Messi H. J. and Montgomery, Jacob M. and Lai, Calvin K.},
  year = {2024},
  month = jan,
  number = {arXiv:2401.08495},
  eprint = {2401.08495},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2401.08495},
  url = {https://arxiv.org/abs/2401.08495},
  pdf={lee_effect_2024.pdf},
  urldate = {2024-01-20},
  abstract = {Large Language Models (LLMs) have become pervasive in everyday life, yet their inner workings remain opaque. While scholarly efforts have demonstrated LLMs' propensity to reproduce biases in their training data, they have primarily focused on the association of social groups with stereotypic attributes. In this paper, we extend this line of inquiry to investigate a bias akin to the social-psychological phenomenon where socially dominant groups are perceived to be less homogeneous than socially subordinate groups as it is reproduced by LLMs. We had ChatGPT, a state-of-the-art LLM, generate a diversity of texts about intersectional group identities and compared text homogeneity. We consistently find that LLMs portray African, Asian, and Hispanic Americans as more homogeneous than White Americans. They also portray women as more homogeneous than men, but these differences are small. Finally, we find that the effect of gender differs across racial/ethnic groups such that the effect of gender is consistent within African and Hispanic Americans but not within Asian and White Americans. We speculate possible sources of this bias in LLMs and posit that the bias has the potential to amplify biases in future LLM training and to reinforce stereotypes.},
  archiveprefix = {arxiv},
  copyright = {All rights reserved},
  keywords = {Computer Science - Computation and Language}, 
  selected = {true}
}

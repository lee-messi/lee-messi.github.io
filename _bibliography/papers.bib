---

@misc{lee_large_2024,
  title = {Large {{Language Models Portray Socially Subordinate Groups}} as {{More Homogeneous}}, {{Consistent}} with a {{Bias Observed}} in {{Humans}}},
  author = {Lee, Messi H. J. and Montgomery, Jacob M. and Lai, Calvin K.},
  year = {2024},
  month = apr,
  eprint = {2401.08495},
  primaryclass = {cs},
  doi = {10.1145/3630106.3658975},
  urldate = {2024-04-29},
  abstract = {Large language models (LLMs) are becoming pervasive in everyday life, yet their propensity to reproduce biases inherited from training data remains a pressing concern. Prior investigations into bias in LLMs have focused on the association of social groups with stereotypical attributes. However, this is only one form of human bias such systems may reproduce. We investigate a new form of bias in LLMs that resembles a social psychological phenomenon where socially subordinate groups are perceived as more homogeneous than socially dominant groups. We had ChatGPT, a state-of-the-art LLM, generate texts about intersectional group identities and compared those texts on measures of homogeneity. We consistently found that ChatGPT portrayed African, Asian, and Hispanic Americans as more homogeneous than White Americans, indicating that the model described racial minority groups with a narrower range of human experience. ChatGPT also portrayed women as more homogeneous than men, but these differences were small. Finally, we found that the effect of gender differed across racial/ethnic groups such that the effect of gender was consistent within African and Hispanic Americans but not within Asian and White Americans. We argue that the tendency of LLMs to describe groups as less diverse risks perpetuating stereotypes and discriminatory behavior.},
  archiveprefix = {arxiv},
  copyright = {All rights reserved},
  keywords = {Computer Science - Computation and Language},
  selected = {true},
  pdf = {}
}

@article{lee_americas_2024,
  title = {America's Racial Framework of Superiority and {{Americanness}} Embedded in Natural Language},
  author = {Lee, Messi H. J. and Montgomery, Jacob M. and Lai, Calvin K.},
  year = {2024},
  month = jan,
  journal = {PNAS Nexus},
  volume = {3},
  number = {1},
  pages = {pgad485},
  issn = {2752-6542},
  doi = {10.1093/pnasnexus/pgad485},
  url = {https://academic.oup.com/pnasnexus/article/3/1/pgad485/7504812}, 
  urldate = {2024-01-27},
  abstract = {America's racial framework can be summarized using two distinct dimensions: superiority/inferiority and Americanness/foreignness. We investigated America's racial framework in a corpus of spoken and written language using word embeddings. Word embeddings place words on a low-dimensional space where words with similar meanings are proximate, allowing researchers to test whether the positions of group and attribute words in a semantic space reflect stereotypes. We trained a word embedding model on the Corpus of Contemporary American English{\textemdash}a corpus of 1 billion words that span 30 years and 8 text categories{\textemdash}and compared the positions of racial/ethnic groups with respect to superiority and Americanness. We found that America's racial framework is embedded in American English. We also captured an additional nuance: Asian people were stereotyped as more American than Hispanic people. These results are empirical evidence that America's racial framework is embedded in American English.},
  copyright = {All rights reserved},
  selected = {true},
  pdf = {lee_americas_2024.pdf}
}


<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Homogeneity Bias as Differential Sampling Uncertainty | Messi H.J. Lee </title> <meta name="author" content="Messi H.J. Lee"> <meta name="description" content="Introduction to a new paper"> <meta name="keywords" content="messi-lee, messi"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/player.png?df84975eea3e18255b788f9afa38f7e9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lee-messi.github.io/blog/2025/sampling-uncertainty/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Messi</span> H.J. Lee </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Homogeneity Bias as Differential Sampling Uncertainty</h1> <p class="post-meta"> February 04, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Recently, I came across an interesting paper investigating how regularizing attention weights could encourage BERT-like models to consider broader token contexts when constructing token-level representations thereby mitigating social biases (Attanasio et al., 2022). That’s quite technical, so let me walk you through what it means in simpler terms.</p> <h2 id="the-connection-between-attention-and-bias">The Connection between Attention and Bias</h2> <p>Think of attention in NLP models like a spotlight. When a model processes a word (token), it shines this spotlight on other words in the context to understand its meaning. For example, when processing the word “doctor,” traditional models might shine a very bright spotlight on words like “he” and a dimmer one on “she” - because that’s the pattern they learned from training data.</p> <p>The key idea behind attention regularization is to intentionally diffuse this spotlight–instead of having intense focus on specific gender-associated words, we want the model to distribute its attention more evenly. Here’s a way to think about it:</p> <p>In a normal setup, when processing “doctor”, the attention weights might look like:</p> <ul> <li>“he”: 0.7</li> <li>“she”: 0.2</li> <li>non-gendered pronouns: 0.1</li> </ul> <p>With regularization, we push for more balanced attention:</p> <ul> <li>“he”: 0.4</li> <li>“she”: 0.4</li> <li>non-gendered pronouns: 0.2</li> </ul> <p>By enforcing this more uniform distribution of attention, we reduce the model’s tendency to strongly associate certain professions with specific genders. It’s like telling the model: “Don’t jump to conclusions about gender when you’re thinking about occupations.”</p> <h2 id="how-it-relates-to-homogeneity-bias">How it Relates to Homogeneity Bias</h2> <p>This work on regularizing attention weights to mitigate social bias led me to consider homogeneity bias from a new angle. What if homogeneity bias in language models manifests from how these models sample tokens during inference? Specifically, when generating text about marginalized groups, the token sampling distribution might become more deterministic, focusing on a narrower set of possible next words.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-04-sampling-uncertainty/study_design-480.webp 480w,/assets/img/2025-02-04-sampling-uncertainty/study_design-800.webp 800w,/assets/img/2025-02-04-sampling-uncertainty/study_design-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-02-04-sampling-uncertainty/study_design.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>We tested this idea using Vision-Language Models as our experimental setup. We asked these models to generate stories about images showing different racial and gender groups, then carefully tracked how the models made their word choices. To measure this scientifically, we used three different metrics: entropy, perplexity, and probability of differentiation. These metrics helped us understand if the model was more predictable when writing about certain groups versus others-similar to how a recommendation system might fall back on popular, safe suggestions when it has limited data about a user’s preferences.</p> <h2 id="results">Results</h2> <p>Our initial analysis with GPT-4 Turbo revealed a consistent pattern: when generating text, the model showed significantly lower uncertainty in its word choices when writing about Black Americans and women compared to White Americans and men. This pattern held true across all 50 token positions we analyzed.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-04-sampling-uncertainty/race-480.webp 480w,/assets/img/2025-02-04-sampling-uncertainty/race-800.webp 800w,/assets/img/2025-02-04-sampling-uncertainty/race-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-02-04-sampling-uncertainty/race.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>To verify whether this pattern was unique to GPT-4 Turbo, we expanded our analysis to include three additional models: GPT-4o mini, Llama-3.2, and Ovis-1.6. Llama-3.2 exhibited similar patterns to GPT-4 Turbo, while GPT-4o mini and Ovis-1.6 either showed no significant differences or displayed opposite patterns in their token sampling behavior.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-04-sampling-uncertainty/race_position-480.webp 480w,/assets/img/2025-02-04-sampling-uncertainty/race_position-800.webp 800w,/assets/img/2025-02-04-sampling-uncertainty/race_position-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-02-04-sampling-uncertainty/race_position.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The visualizations above demonstrate consistently lower measures across token positions for Black Americans compared to White Americans, indicating more deterministic token sampling distributions for Black Americans.</p> <h2 id="the-significance-of-this-work">The Significance of this Work</h2> <p>Our approach offers a new way to understand homogeneity bias in language models by looking directly at how these models make word choices during text generation. Previous methods relied on using encoder models to analyze the final generated text, but these methods shared a fatal limitation: these encoder models might share the same biases as the models being studied, making it harder to isolate different sources of bias.</p> <p>By examining token sampling distributions during inference, we get a more direct window into how these models actually behave when generating text. Rather than looking at the end product, we’re observing the model’s decision-making process in real-time – specifically, how certain or uncertain it is when choosing words for different groups. This mechanistic approach helps us pinpoint where and how homogeneity bias manifests in the generation process, opening new possibilities for addressing these biases at their source.</p> <h3 id="references">References</h3> <p>Lee, M. H. J., &amp; Jeon, S. (2025). Homogeneity Bias as Differential Sampling Uncertainty in Language Models (arXiv:2501.19337). arXiv. https://doi.org/10.48550/arXiv.2501.19337</p> <p>Attanasio, G., Nozza, D., Hovy, D., &amp; Baralis, E. (2022). Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists (arXiv:2203.09192). arXiv. https://doi.org/10.48550/arXiv.2203.09192</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/homogeneity-bias/">Homogeneity Bias in Large Language Models</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Messi H.J. Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Favicon by <a href="https://www.flaticon.com/free-icons/messi" title="messi icons" rel="external nofollow noopener" target="_blank">Hopstarter - Flaticon</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: February 06, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>